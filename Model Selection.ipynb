{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDWSAWprShN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def save(model, filename='bestmodel.pickle'):\n",
        "    with open('output/'+filename, 'wb') as handle:\n",
        "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "def submit(model):\n",
        "    model = model.fit(train_x,train_y)\n",
        "    pred = model.predict(final_test)\n",
        "    final_test['SalePrice'] = np.exp(pred)\n",
        "    final_test[['Id','SalePrice']].to_csv('output/submission.csv', index=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3whduyAbrShU",
        "colab_type": "code",
        "outputId": "ee37d5cf-5d0f-4de2-c51b-9a622e6998a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "#make train and test datasets. Splitting labels and features happens later\n",
        "path_train = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/train.csv\"\n",
        "path_test = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/test.csv\"\n",
        "\n",
        "train = pd.read_csv(path_train)\n",
        "final_test = pd.read_csv(path_test)\n",
        "print(train.shape, final_test.shape)\n",
        "\n",
        "y_col = (set(train.columns) - set(final_test.columns)).pop()\n",
        "train[y_col] = np.log1p(train[y_col])\n",
        "\n",
        "# since we use cross validation the train set does not have to be split anymore\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_x, test_x, train_y, test_y = train_test_split(\n",
        "#     train.drop([y_col], axis=1),train.loc[:,y_col], test_size=0.33, random_state=42) \n",
        "# ds = (train_x,test_x,train_y,test_y)\n",
        "# for d in ds: print(d.shape)\n",
        "train_x = train.drop([y_col], axis=1)\n",
        "train_y = train.loc[:,y_col]\n",
        "train_x.shape, train_y.shape\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1460, 81) (1459, 80)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1460, 80), (1460,))"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPXAZImebs9C",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d_1GRqKMm1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correlation_ratio(categories, measurements):\n",
        "    fcat, _ = pd.factorize(categories)\n",
        "    cat_num = np.max(fcat)+1\n",
        "    y_avg_array = np.zeros(cat_num)\n",
        "    n_array = np.zeros(cat_num)\n",
        "    for i in range(0,cat_num):\n",
        "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
        "        n_array[i] = len(cat_measures)\n",
        "        y_avg_array[i] = np.average(cat_measures)\n",
        "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
        "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
        "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
        "    if numerator == 0:\n",
        "        eta = 0.0\n",
        "    else:\n",
        "        eta = np.sqrt(numerator/denominator)\n",
        "    return eta\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi2Hnpq0JJTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "# todo multivariate imputation, possibly with pipelines for numeric and categorical data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "# https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler/51237727\n",
        "# don't know features are normal so just going with minmax scalar atm\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#https://stackoverflow.com/questions/36631163/what-are-the-pros-and-cons-between-get-dummies-pandas-and-onehotencoder-sciki\n",
        "#The crux of it is that the sklearn encoder creates a function which persists and can then be applied to new data sets which use the same categorical variables, with consistent results.\n",
        "# So don't use pandas get dummies, but a OneHotEncoder\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "corr = train.corr()[y_col]\n",
        "corr = corr.sort_values(ascending=False)\n",
        "num_x = list(corr.index)[1:]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('impute_num', SimpleImputer(strategy='median')),\n",
        "    ('scale_num', MinMaxScaler())])\n",
        "\n",
        "cat_x = [col for col in final_test.columns if final_test[col].dtype == 'object']\n",
        "cat_x.sort(key = lambda x: -correlation_ratio(train[x],train[y_col]))\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('impute_cat', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot_cat', OneHotEncoder(handle_unknown=\"ignore\"))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numeric_transformer, num_x),\n",
        "        ('category', categorical_transformer, cat_x)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azoNOEDFbs9F",
        "colab_type": "text"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "7Zi4dfYbbs9G",
        "colab_type": "code",
        "outputId": "7ee5f87c-b225-452f-9632-d7182229d4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "\n",
        "# from catboost import CatBoostRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet,SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_validate\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def inv_y(transformed_y):\n",
        "    return np.exp(transformed_y)\n",
        "\n",
        "from collections import namedtuple\n",
        "p = namedtuple('params', ['model','hyper'])\n",
        "\n",
        "models = {'RidgeCV': p(RidgeCV(),\n",
        "                {}),\n",
        "            'svm.SVR': p(svm.SVR(),\n",
        "                {'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],\n",
        "                'C': [1, 10, 100, 1000, 10000]}),\n",
        "            'LinearRegression':p(LinearRegression(),\n",
        "                {}),\n",
        "            'Lasso':p(Lasso(),\n",
        "                {'alpha':(0.005,1.0,'log-uniform')}),\n",
        "            'ElasticNet':p(ElasticNet(),\n",
        "                {}),\n",
        "            'KNeighborsRegressor':p(KNeighborsRegressor(),\n",
        "                {}),\n",
        "            'RandomForestRegressor':p(RandomForestRegressor(),\n",
        "                {}),\n",
        "            'SGDRegressor':p(SGDRegressor(),\n",
        "                {}),\n",
        "            'CatBoostRegressor':p(CatBoostRegressor(silent=True),\n",
        "                {}),\n",
        "            'xgb.XGBRegressor':p(xgb.XGBRegressor(),\n",
        "                {}),\n",
        "            'lgb.LGBMRegressor':\n",
        "                p(lgb.LGBMRegressor(num_leaves=31,\n",
        "                        learning_rate=0.05,\n",
        "                        n_estimators=20),\n",
        "                {}),\n",
        "            'HistGradientBoostingRegressor':p(HistGradientBoostingRegressor(),\n",
        "                {}),\n",
        "            'MLPRegressor':p(MLPRegressor(),\n",
        "                {})\n",
        "}\n",
        "\n",
        "def get_pipeline(model):\n",
        "    return Pipeline([('preprocess', preprocessor),\n",
        "                   ('model',model)])\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RidgeCV                  train 0.115, test 0.143\nsvm.SVR                  train 0.088, test 0.141\nLinearRegression         train 0.089, test 0.151\nLasso                    train 0.399, test 0.399\nElasticNet               train 0.399, test 0.399\nKNeighborsRegressor      train 0.169, test 0.215\nRandomForestRegressor    train 0.055, test 0.147\nSGDRegressor             train 0.196, test 0.234\nCatBoostRegressor        train 0.032, test 0.122\nxgb.XGBRegressor         train 0.005, test 0.150\nlgb.LGBMRegressor        train 0.190, test 0.211\nHistGradientBoostingRegressortrain nan, test nan\nMLPRegressor             train 0.136, test 0.201\n"
        }
      ],
      "source": [
        "for name in models:\n",
        "    pipe = get_pipeline(models[name].model)\n",
        "    # score = -1 * cross_val_score(pipe, train_x, train_y,cv=3,scoring='neg_root_mean_squared_error')\n",
        "    # below is necessary for looking at train scores\n",
        "    num_fold = 3\n",
        "    scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "    # scoring is identical to \n",
        "    # make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "    # neg_mean_squared_log_error\n",
        "    print(f\"{name:<25}train {-1 * sum(scores['train_score'])/num_fold:.3f}, test {-1 * sum(scores['test_score'])/num_fold:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "dict_keys(['memory', 'steps', 'verbose', 'preprocess', 'model', 'preprocess__n_jobs', 'preprocess__remainder', 'preprocess__sparse_threshold', 'preprocess__transformer_weights', 'preprocess__transformers', 'preprocess__verbose', 'preprocess__numeric', 'preprocess__category', 'preprocess__numeric__memory', 'preprocess__numeric__steps', 'preprocess__numeric__verbose', 'preprocess__numeric__impute_num', 'preprocess__numeric__scale_num', 'preprocess__numeric__impute_num__add_indicator', 'preprocess__numeric__impute_num__copy', 'preprocess__numeric__impute_num__fill_value', 'preprocess__numeric__impute_num__missing_values', 'preprocess__numeric__impute_num__strategy', 'preprocess__numeric__impute_num__verbose', 'preprocess__numeric__scale_num__copy', 'preprocess__numeric__scale_num__feature_range', 'preprocess__category__memory', 'preprocess__category__steps', 'preprocess__category__verbose', 'preprocess__category__impute_cat', 'preprocess__category__onehot_cat', 'preprocess__category__impute_cat__add_indicator', 'preprocess__category__impute_cat__copy', 'preprocess__category__impute_cat__fill_value', 'preprocess__category__impute_cat__missing_values', 'preprocess__category__impute_cat__strategy', 'preprocess__category__impute_cat__verbose', 'preprocess__category__onehot_cat__categories', 'preprocess__category__onehot_cat__drop', 'preprocess__category__onehot_cat__dtype', 'preprocess__category__onehot_cat__handle_unknown', 'preprocess__category__onehot_cat__sparse', 'model__alpha', 'model__copy_X', 'model__fit_intercept', 'model__max_iter', 'model__normalize', 'model__positive', 'model__precompute', 'model__random_state', 'model__selection', 'model__tol', 'model__warm_start'])"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "pipe = get_pipeline(Lasso())\n",
        "pipe.get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVRX7I7yimmP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wO5qirPMBqGX"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from aoc import timeit\n",
        "\n",
        "def model_instance(model_name):\n",
        "    model = {'model': [models[model_name].model]}\n",
        "    for k,v in models[model_name].hyper.items():\n",
        "        model['model__'+k] = v\n",
        "    return (model, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n      max_iter=1000, normalize=False, positive=False, precompute=False,\n      random_state=None, selection='cyclic', tol=0.0001, warm_start=False), 0.006038940085472412]\nbest score     -0.1471770010322478\n[Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n      max_iter=1000, normalize=False, positive=False, precompute=False,\n      random_state=None, selection='cyclic', tol=0.0001, warm_start=False), 0.006038940085472412]\nbest score     -0.1471770010322478\n[Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n      max_iter=1000, normalize=False, positive=False, precompute=False,\n      random_state=None, selection='cyclic', tol=0.0001, warm_start=False), 0.006038940085472412]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 10, 0.9]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.001]\nbest score     -0.1471770010322478\n"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Can only compute distance for values within the space, not SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel=\"SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\",\n    max_iter=-1, shrinking=True, tol=0.001, verbose=False) and SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False).",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-41-af654fa6733d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2x2 20 iter cv=3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mon_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"val. score: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[0;32m    678\u001b[0m                 optim_result = self._step(\n\u001b[0;32m    679\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m                     \u001b[0mgroups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m                 )\n\u001b[0;32m    682\u001b[0m                 \u001b[0mn_iter\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mn_points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;31m# get parameter values to evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m         \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;31m# convert parameters to python native types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36mask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_points\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36mask\u001b[1;34m(self, n_points, strategy)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_points\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0msupported_strategies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"cl_min\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cl_mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cl_max\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36m_ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             min_delta_x = min([self.space.distance(next_x, xi)\n\u001b[1;32m--> 407\u001b[1;33m                                for xi in self.Xi])\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_delta_x\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1e-8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 warnings.warn(\"The objective has been evaluated \"\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_x\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             min_delta_x = min([self.space.distance(next_x, xi)\n\u001b[1;32m--> 407\u001b[1;33m                                for xi in self.Xi])\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_delta_x\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1e-8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 warnings.warn(\"The objective has been evaluated \"\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\space\\space.py\u001b[0m in \u001b[0;36mdistance\u001b[1;34m(self, point_a, point_b)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoint_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m             \u001b[0mdistance\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Miniconda3\\lib\\site-packages\\skopt\\space\\space.py\u001b[0m in \u001b[0;36mdistance\u001b[1;34m(self, a, b)\u001b[0m\n\u001b[0;32m    625\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             raise RuntimeError(\"Can only compute distance for values within\"\n\u001b[1;32m--> 627\u001b[1;33m                                \" the space, not {} and {}.\".format(a, b))\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Can only compute distance for values within the space, not SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel=\"SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\",\n    max_iter=-1, shrinking=True, tol=0.001, verbose=False) and SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)."
          ]
        }
      ],
      "source": [
        "\n",
        "# callback handler\n",
        "train_status = { 'current_score': -100, 'not_improving': 0, 'stop_thres' : 2}\n",
        "def on_step(optim_result):\n",
        "    score = opt.best_score_\n",
        "    print(optim_result.x)\n",
        "    print(f\"{'best score':15}{score}\")\n",
        "    # print(f\"{'current score':15}{train_status['current_score']}\")\n",
        "    # print(f\"{'difference':15}{train_status['current_score']-score}\")\n",
        "    # print(f\"{'nip':15}{train_status['not_improving']}\")\n",
        "\n",
        "    if score > train_status['current_score']:\n",
        "        # print('improv')\n",
        "        train_status['current_score'] = score\n",
        "        train_status['not_improving'] = 0\n",
        "    else:\n",
        "        # print('NOT')\n",
        "        train_status['not_improving'] += 1\n",
        "        if train_status['not_improving'] == train_status['stop_thres']: return True\n",
        "\n",
        "pipe = get_pipeline(svm.SVR())\n",
        "to_test = ['Lasso','svm.SVR']\n",
        "opt = BayesSearchCV(\n",
        "    pipe,\n",
        "    [model_instance(name) for name in to_test],\n",
        "    # cv=3, \n",
        "    scoring = 'neg_root_mean_squared_error',\n",
        "    return_train_score = True,\n",
        "    random_state = 112 # (parameter space, # of evaluations)\n",
        ")\n",
        "\n",
        "with timeit('2x2 20 iter cv=3'): opt.fit(train_x[:1000],train_y[:1000], callback = on_step)\n",
        "print(\"val. score: %s\" % opt.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'model': [SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n      kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)],\n 'model__C': (1e-06, 1000000.0, 'log-uniform')}"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "linsvc_search = {\n",
        "    'model': [svm.SVR(max_iter=1000)],\n",
        "    'model__C': (1e-6, 1e+6, 'log-uniform'),\n",
        "}\n",
        "linsvc_search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "OrderedDict([('model__C', 2885), ('model__gamma', 0.0001)])"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "opt.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hLsUZ1ZnBp5P"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_info = (train_x, train_y, num_x, cat_x)\n",
        "with open('output/train_info.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wvgdkTRBptT",
        "colab_type": "code",
        "colab": {},
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "model = get_pipeline(CatBoostRegressor(silent=True))\n",
        "submit(model)\n",
        "save(model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0twqEdSiBpgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gJCjBEBBpSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2qnmlMeBonj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Jm2LQ4BoSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_BEY8s3Uowo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ridge, \t        train 0.115, test 0.143\n",
        "svm, \t        train 0.088, test 0.141\n",
        "lin, \t        train 0.089, test 0.151\n",
        "lasso, \t        train 0.109, test 0.137\n",
        "ElasticNet, \ttrain 0.399, test 0.399\n",
        "GammaRegressor, train 0.248, test 0.251\n",
        "KNeighborsRegrestrain 0.169, test 0.215\n",
        "RandomForestRegrtrain 0.056, test 0.147\n",
        "SGDRegressor, \ttrain 0.196, test 0.233\n",
        "CatBoostRegressotrain 0.032, test 0.122\n",
        "xgb.XGBRegressortrain 0.005, test 0.150\n",
        "lgb.LGBMRegressotrain 0.190, test 0.211\n",
        "HistGradientBoostrain nan, test nan\n",
        "MLPRegressor, \ttrain 0.138, test 0.196"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
      "language": "python",
      "name": "python37364bitprogramdatavirtualenv99403c2e8abd4ba0909557516bfee9d9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "colab": {
      "name": "Copy of Copy of Copy of rentJesse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}