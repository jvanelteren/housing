{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDWSAWprShN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def save(model, filename='bestmodel.pickle'):\n",
        "    with open('output/'+filename, 'wb') as handle:\n",
        "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "def submit(model):\n",
        "    model = model.fit(train_x,train_y)\n",
        "    pred = model.predict(final_test)\n",
        "    final_test['SalePrice'] = np.exp(pred)\n",
        "    final_test[['Id','SalePrice']].to_csv('output/submission.csv', index=False)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3whduyAbrShU",
        "colab_type": "code",
        "outputId": "ee37d5cf-5d0f-4de2-c51b-9a622e6998a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "#make train and test datasets. Splitting labels and features happens later\n",
        "path_train = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/train.csv\"\n",
        "path_test = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/test.csv\"\n",
        "\n",
        "train = pd.read_csv(path_train)\n",
        "final_test = pd.read_csv(path_test)\n",
        "print(train.shape, final_test.shape)\n",
        "\n",
        "y_col = (set(train.columns) - set(final_test.columns)).pop()\n",
        "train[y_col] = np.log1p(train[y_col])\n",
        "\n",
        "# since we use cross validation the train set does not have to be split anymore\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_x, test_x, train_y, test_y = train_test_split(\n",
        "#     train.drop([y_col], axis=1),train.loc[:,y_col], test_size=0.33, random_state=42) \n",
        "# ds = (train_x,test_x,train_y,test_y)\n",
        "# for d in ds: print(d.shape)\n",
        "train_x = train.drop([y_col], axis=1)\n",
        "train_y = train.loc[:,y_col]\n",
        "train_x.shape, train_y.shape\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1460, 81) (1459, 80)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1460, 80), (1460,))"
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPXAZImebs9C",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d_1GRqKMm1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correlation_ratio(categories, measurements):\n",
        "    fcat, _ = pd.factorize(categories)\n",
        "    cat_num = np.max(fcat)+1\n",
        "    y_avg_array = np.zeros(cat_num)\n",
        "    n_array = np.zeros(cat_num)\n",
        "    for i in range(0,cat_num):\n",
        "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
        "        n_array[i] = len(cat_measures)\n",
        "        y_avg_array[i] = np.average(cat_measures)\n",
        "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
        "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
        "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
        "    if numerator == 0:\n",
        "        eta = 0.0\n",
        "    else:\n",
        "        eta = np.sqrt(numerator/denominator)\n",
        "    return eta\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi2Hnpq0JJTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "# todo multivariate imputation, possibly with pipelines for numeric and categorical data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "# https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler/51237727\n",
        "# don't know features are normal so just going with minmax scalar atm\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#https://stackoverflow.com/questions/36631163/what-are-the-pros-and-cons-between-get-dummies-pandas-and-onehotencoder-sciki\n",
        "#The crux of it is that the sklearn encoder creates a function which persists and can then be applied to new data sets which use the same categorical variables, with consistent results.\n",
        "# So don't use pandas get dummies, but a OneHotEncoder\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "corr = train.corr()[y_col]\n",
        "corr = corr.sort_values(ascending=False)\n",
        "num_x = list(corr.index)[1:]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('impute_num', SimpleImputer(strategy='median')),\n",
        "    ('scale_num', MinMaxScaler())])\n",
        "\n",
        "cat_x = [col for col in final_test.columns if final_test[col].dtype == 'object']\n",
        "cat_x.sort(key = lambda x: -correlation_ratio(train[x],train[y_col]))\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('impute_cat', SimpleImputer(strategy='most_frequent')),\n",
        "    # ('onehot_cat', OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numeric_transformer, num_x),\n",
        "        ('category', categorical_transformer, cat_x)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azoNOEDFbs9F",
        "colab_type": "text"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "7Zi4dfYbbs9G",
        "colab_type": "code",
        "outputId": "7ee5f87c-b225-452f-9632-d7182229d4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "\n",
        "# from catboost import CatBoostRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet,SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_validate\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def inv_y(transformed_y):\n",
        "    return np.exp(transformed_y)\n",
        "\n",
        "from collections import namedtuple\n",
        "p = namedtuple('params', ['model','hyper'])\n",
        "\n",
        "models = {'Ridge': p(Ridge(),\n",
        "                {'alpha':(0.00001,1.0,'log-uniform')}),\n",
        "            'svm.SVR': p(svm.SVR(),\n",
        "                {'gamma': (1e-4,0.9,'log-uniform'),\n",
        "                'C': [1, 10, 100, 1000, 10000]}),\n",
        "            'LinearRegression':p(LinearRegression(),\n",
        "                {}),\n",
        "            'Lasso':p(Lasso(),\n",
        "                {'alpha':(0.00001,1.0,'log-uniform')}),\n",
        "            'ElasticNet':p(ElasticNet(),\n",
        "                {}),\n",
        "            'KNeighborsRegressor':p(KNeighborsRegressor(),\n",
        "                {}),\n",
        "            'RandomForestRegressor':p(RandomForestRegressor(),\n",
        "                {'n_estimators' : (1e-4,0.9,'log-uniform'),\n",
        "                'max_depth' : [3, 10, 20, 40]}),\n",
        "            'SGDRegressor':p(SGDRegressor(),\n",
        "                {'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        "                'penalty' : ['l1', 'l2', 'elasticnet'],\n",
        "                'alpha' : (0.0,1000,'log-uniform'),\n",
        "                'learning_rate' : ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
        "                'class_weight' : [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
        "                'eta0' : [1, 10, 100]}),\n",
        "            'CatBoostRegressor':p(CatBoostRegressor(silent=True),\n",
        "                {}),\n",
        "            'xgb.XGBRegressor':p(xgb.XGBRegressor(),\n",
        "                {'max_depth': [4, 16, 1],\n",
        "                'min_child_weight': (1, 10, 1),\n",
        "                'subsample': (0.7, 1),\n",
        "                'gamma' : (0.1,0.5),\n",
        "                'colsample_bytree' : (0.7,1),\n",
        "                'reg_lambda' : (0,1)}),\n",
        "            'lgb.LGBMRegressor':\n",
        "                p(lgb.LGBMRegressor(num_leaves=31,\n",
        "                        learning_rate=0.05,\n",
        "                        n_estimators=20),\n",
        "                {}),\n",
        "            'HistGradientBoostingRegressor':p(HistGradientBoostingRegressor(),\n",
        "                {}),\n",
        "            'LassoCV':p(LassoCV(),\n",
        "                {}),\n",
        "            'MLPRegressor':p(MLPRegressor(),\n",
        "                {})\n",
        "}\n",
        "\n",
        "# Logistic\n",
        "# penalty = ['l1', 'l2']\n",
        "# C = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
        "# class_weight = [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}]\n",
        "\n",
        "def get_pipeline(model):\n",
        "    return Pipeline([('preprocess', preprocessor),\n",
        "                   ('model',model)])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "SaleCondition            train 0.033, test 0.120\n"
        }
      ],
      "source": [
        "for name in train_x.columns:\n",
        "    if name in cat_x:\n",
        "        train_x[name] = train_x[name].astype(str)\n",
        "        train_x[name].apply(str)\n",
        "cat_x_ind = [ind for ind,name in enumerate(train_x.columns) if name in cat_x ]\n",
        "cat_x_ind = list(range(37,80))\n",
        "pipe = get_pipeline(CatBoostRegressor(silent=True,one_hot_max_size=20, cat_features = cat_x_ind))\n",
        "num_fold = 3\n",
        "scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "# scoring is identical to \n",
        "# make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "# neg_mean_squared_log_error\n",
        "print(f\"{name:<25}train {-1 * sum(scores['train_score'])/num_fold:.3f}, test {-1 * sum(scores['test_score'])/num_fold:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "37"
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "len(num_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0          1\n1          2\n2          3\n3          4\n4          5\n        ... \n1455    1456\n1456    1457\n1457    1458\n1458    1459\n1459    1460\nName: Id, Length: 1460, dtype: object"
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "train_x['Id'].astype(str)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "80"
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "len(x[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cross_val_models(to_test):\n",
        "    for name in to_test:\n",
        "        print(name)\n",
        "        pipe = get_pipeline(models[name].model)\n",
        "        # score = -1 * cross_val_score(pipe, train_x, train_y,cv=3,scoring='neg_root_mean_squared_error')\n",
        "        # below is necessary for looking at train scores\n",
        "        num_fold = 3\n",
        "        scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "        # scoring is identical to \n",
        "        # make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "        # neg_mean_squared_log_error\n",
        "        print(f\"{name:<25}train {-1 * sum(scores['train_score'])/num_fold:.3f}, test {-1 * sum(scores['test_score'])/num_fold:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVRX7I7yimmP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wO5qirPMBqGX"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "best score     -0.22016394104958886\nbest score     -0.15103038400115953\nbest score     -0.14670236053304353\nbest score     -0.14670236053304353\nbest score     -0.1361014811618008\nbest score     -0.1361014811618008\nbest score     -0.1361014811618008\nbest score     -0.1352495930390204\nbest score     -0.1352495930390204\nbest score     -0.1352495930390204\nbest score     -0.1352495930390204\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.1348139379074011\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13480610660535308\nbest score     -0.13479551731346873\nbest score     -0.13479551731346873\nINFO:root:fittingLasso, time: 5.2289586385091145\n"
        }
      ],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from aoc import timeit\n",
        "\n",
        "def model_instance(model_name):\n",
        "    model = {'model': [models[model_name].model]}\n",
        "    for k,v in models[model_name].hyper.items():\n",
        "        model['model__'+k] = v\n",
        "    return (model, 50)\n",
        "\n",
        "def run_model(name):\n",
        "    def on_step(optim_result):\n",
        "        score = opt.best_score_\n",
        "        print(f\"{'best score':15}{score}\")\n",
        "        if score > opt.train_status['current_score']:\n",
        "            opt.train_status['current_score'] = score\n",
        "            opt.train_status['not_improving'] = 0\n",
        "        else:\n",
        "            opt.train_status['not_improving'] += 1\n",
        "            if opt.train_status['not_improving'] == opt.train_status['stop_thres']: return True\n",
        "\n",
        "    opt = BayesSearchCV(\n",
        "    pipe,\n",
        "    [model_instance(name)],\n",
        "    cv=5, \n",
        "    scoring = 'neg_root_mean_squared_error',\n",
        "    return_train_score = True,\n",
        "    random_state = 112 \n",
        "    )\n",
        "    opt.train_status = { 'current_score': -100, 'not_improving': 0, 'stop_thres' : 20}\n",
        "\n",
        "    with timeit('fitting'+name): opt.fit(train_x,train_y, callback = on_step)\n",
        "    return opt\n",
        "\n",
        "pipe = get_pipeline(svm.SVR())\n",
        "to_test = ['Lasso']\n",
        "test_results = {name: run_model(name) for name in to_test}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "-0.13479551731346873"
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# test_results['Lasso'].cv_results_\n",
        "test_results['Lasso'].best_params_\n",
        "test_results['Lasso'].best_score_\n",
        "# test_results['Lasso'].total_iterations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLPRegressor             train 0.1090, test 0.1348\n"
        }
      ],
      "source": [
        "pipe = get_pipeline(Lasso(alpha=0.0006016868735786635))\n",
        "# score = -1 * cross_val_score(pipe, train_x, train_y,cv=3,scoring='neg_root_mean_squared_error')\n",
        "# below is necessary for looking at train scores\n",
        "num_fold = 5\n",
        "scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "# scoring is identical to \n",
        "# make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "# neg_mean_squared_log_error\n",
        "print(f\"{name:<25}train {-1 * sum(scores['train_score'])/num_fold:.4f}, test {-1 * sum(scores['test_score'])/num_fold:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "MLPRegressor             train 0.1107, test 0.1350\n"
        }
      ],
      "source": [
        "pipe = get_pipeline(Lasso(alpha=0.0006607161323268261))\n",
        "# score = -1 * cross_val_score(pipe, train_x, train_y,cv=3,scoring='neg_root_mean_squared_error')\n",
        "# below is necessary for looking at train scores\n",
        "num_fold = 5\n",
        "scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "# scoring is identical to \n",
        "# make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "# neg_mean_squared_log_error\n",
        "print(f\"{name:<25}train {-1 * sum(scores['train_score'])/num_fold:.4f}, test {-1 * sum(scores['test_score'])/num_fold:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hLsUZ1ZnBp5P"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_info = (train_x, train_y, num_x, cat_x)\n",
        "with open('output/train_info.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wvgdkTRBptT",
        "colab_type": "code",
        "colab": {},
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "model = get_pipeline(CatBoostRegressor(silent=True))\n",
        "submit(model)\n",
        "save(model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0twqEdSiBpgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gJCjBEBBpSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2qnmlMeBonj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Jm2LQ4BoSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
      "language": "python",
      "name": "python37364bitprogramdatavirtualenv99403c2e8abd4ba0909557516bfee9d9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "colab": {
      "name": "Copy of Copy of Copy of rentJesse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}