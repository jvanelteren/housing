{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDWSAWprShN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def save(model, filename='bestmodel.pickle'):\n",
        "    with open('output/'+filename, 'wb') as handle:\n",
        "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "def submit(model):\n",
        "    model = model.fit(train_x,train_y)\n",
        "    pred = model.predict(final_test)\n",
        "    final_test['SalePrice'] = np.exp(pred)\n",
        "    final_test[['Id','SalePrice']].to_csv('output/submission.csv', index=False)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3whduyAbrShU",
        "colab_type": "code",
        "outputId": "ee37d5cf-5d0f-4de2-c51b-9a622e6998a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "#make train and test datasets. Splitting labels and features happens later\n",
        "path_train = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/train.csv\"\n",
        "path_test = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/test.csv\"\n",
        "\n",
        "train = pd.read_csv(path_train)\n",
        "final_test = pd.read_csv(path_test)\n",
        "print(train.shape, final_test.shape)\n",
        "\n",
        "y_col = (set(train.columns) - set(final_test.columns)).pop()\n",
        "train[y_col] = np.log1p(train[y_col])\n",
        "\n",
        "# since we use cross validation the train set does not have to be split anymore\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_x, test_x, train_y, test_y = train_test_split(\n",
        "#     train.drop([y_col], axis=1),train.loc[:,y_col], test_size=0.33, random_state=42) \n",
        "# ds = (train_x,test_x,train_y,test_y)\n",
        "# for d in ds: print(d.shape)\n",
        "train_x = train.drop([y_col], axis=1)\n",
        "train_y = train.loc[:,y_col]\n",
        "train_x.shape, train_y.shape\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1460, 81) (1459, 80)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1460, 80), (1460,))"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPXAZImebs9C",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d_1GRqKMm1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correlation_ratio(categories, measurements):\n",
        "    fcat, _ = pd.factorize(categories)\n",
        "    cat_num = np.max(fcat)+1\n",
        "    y_avg_array = np.zeros(cat_num)\n",
        "    n_array = np.zeros(cat_num)\n",
        "    for i in range(0,cat_num):\n",
        "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
        "        n_array[i] = len(cat_measures)\n",
        "        y_avg_array[i] = np.average(cat_measures)\n",
        "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
        "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
        "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
        "    if numerator == 0:\n",
        "        eta = 0.0\n",
        "    else:\n",
        "        eta = np.sqrt(numerator/denominator)\n",
        "    return eta\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi2Hnpq0JJTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "# todo multivariate imputation, possibly with pipelines for numeric and categorical data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "# https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler/51237727\n",
        "# don't know features are normal so just going with minmax scalar atm\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#https://stackoverflow.com/questions/36631163/what-are-the-pros-and-cons-between-get-dummies-pandas-and-onehotencoder-sciki\n",
        "#The crux of it is that the sklearn encoder creates a function which persists and can then be applied to new data sets which use the same categorical variables, with consistent results.\n",
        "# So don't use pandas get dummies, but a OneHotEncoder\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "corr = train.corr()[y_col]\n",
        "corr = corr.sort_values(ascending=False)\n",
        "num_x = list(corr.index)[1:]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('impute_num', SimpleImputer(strategy='median')),\n",
        "    ('scale_num', MinMaxScaler())])\n",
        "\n",
        "cat_x = [col for col in final_test.columns if final_test[col].dtype == 'object']\n",
        "cat_x.sort(key = lambda x: -correlation_ratio(train[x],train[y_col]))\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('impute_cat', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot_cat', OneHotEncoder(handle_unknown=\"ignore\"))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numeric_transformer, num_x),\n",
        "        ('category', categorical_transformer, cat_x)])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azoNOEDFbs9F",
        "colab_type": "text"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "7Zi4dfYbbs9G",
        "colab_type": "code",
        "outputId": "7ee5f87c-b225-452f-9632-d7182229d4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "\n",
        "# from catboost import CatBoostRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet,SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_validate\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def inv_y(transformed_y):\n",
        "    return np.exp(transformed_y)\n",
        "\n",
        "from collections import namedtuple\n",
        "p = namedtuple('params', ['model','hyper'])\n",
        "\n",
        "models = {'RidgeCV': p(RidgeCV(),\n",
        "                {}),\n",
        "            'svm.SVR': p(svm.SVR(),\n",
        "                {'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],\n",
        "                'C': [1, 10, 100, 1000, 10000]}),\n",
        "            'LinearRegression':p(LinearRegression(),\n",
        "                {}),\n",
        "            'Lasso':p(Lasso(),\n",
        "                {}),\n",
        "            'ElasticNet':p(ElasticNet(),\n",
        "                {}),\n",
        "            'KNeighborsRegressor':p(KNeighborsRegressor(),\n",
        "                {}),\n",
        "            'RandomForestRegressor':p(RandomForestRegressor(),\n",
        "                {}),\n",
        "            'SGDRegressor':p(SGDRegressor(),\n",
        "                {}),\n",
        "            'CatBoostRegressor':p(CatBoostRegressor(silent=True),\n",
        "                {}),\n",
        "            'xgb.XGBRegressor':p(xgb.XGBRegressor(),\n",
        "                {}),\n",
        "            'lgb.LGBMRegressor':\n",
        "                p(lgb.LGBMRegressor(num_leaves=31,\n",
        "                        learning_rate=0.05,\n",
        "                        n_estimators=20),\n",
        "                {}),\n",
        "            'HistGradientBoostingRegressor':p(HistGradientBoostingRegressor(),\n",
        "                {}),\n",
        "            'MLPRegressor':p(MLPRegressor(),\n",
        "                {})\n",
        "}\n",
        "\n",
        "def get_pipeline(model):\n",
        "    return Pipeline([('preprocess', preprocessor),\n",
        "                   ('model',model)])\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name, model in models:\n",
        "    pipe = get_pipeline(model)\n",
        "    # score = -1 * cross_val_score(pipe, train_x, train_y,cv=3,scoring='neg_root_mean_squared_error')\n",
        "    # below is necessary for looking at train scores\n",
        "    num_fold = 3\n",
        "    scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "    # scoring is identical to \n",
        "    # make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "    # neg_mean_squared_log_error\n",
        "    print(f\"{name}, \\ttrain {-1 * sum(scores['train_score'])/num_fold:.3f}, test {-1 * sum(scores['test_score'])/num_fold:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "for name in ['svm.SVR']:\n",
        "    pipe = get_pipeline(svm.SVR())\n",
        "    pipe.get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVRX7I7yimmP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wO5qirPMBqGX"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "models['svm.SVR'].model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from aoc import timeit\n",
        "\n",
        "pipe = get_pipeline(svm.SVR())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'model': [SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n      kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)],\n 'model__gamma': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],\n 'model__C': [1, 10, 100, 1000, 10000]}"
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "def model_instance(model_name):\n",
        "    model = {'model': [models[model_name].model]}\n",
        "    for k,v in models[model_name].hyper.items():\n",
        "        model['model__'+k] = v\n",
        "    return (model, 50)\n",
        "a = model_instance('svm.SVR')\n",
        "a[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],\n 'C': [1, 10, 100, 1000, 10000]}"
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "models['svm.SVR'].hyper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'model': [SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n      kernel='rbf', max_iter=1000, shrinking=True, tol=0.001, verbose=False)],\n 'model__gamma': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5, 0.6, 0.9],\n 'model__C': [1, 10, 100, 1000, 10000]}"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "(parameters_svr, 50)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "best score: -0.3887180566689996\nbest score: -0.25282517460241544\nbest score: -0.15595175374839695\nbest score: -0.15595175374839695\nbest score: -0.15595175374839695\nbest score: -0.15595175374839695\nbest score: -0.15595175374839695\nbest score: -0.15595175374839695\nbest score: -0.15595175374839695\nINFO:root:2x2 20 iter cv=3, time: 0.16215632359186807\nval. score: -0.15595175374839695\n"
        }
      ],
      "source": [
        "\n",
        "# callback handler\n",
        "train_status = { 'current_score': -100, 'not_improving': 0, 'stop_thres' : 6}\n",
        "def on_step(optim_result):\n",
        "    score = opt.best_score_\n",
        "    print(\"best score: %s\" % score)\n",
        "    if score > train_status['current_score']:\n",
        "        train_status['current_score'] = score\n",
        "        train_status['not_improving'] = 0\n",
        "    else:\n",
        "        train_status['not_improving'] += 1\n",
        "        if train_status['not_improving'] == train_status['stop_thres']: return True\n",
        "\n",
        "opt = BayesSearchCV(\n",
        "    pipe,\n",
        "    [model_instance('svm.SVR')],\n",
        "    # cv=3, \n",
        "    scoring = 'neg_root_mean_squared_error',\n",
        "    return_train_score = True # (parameter space, # of evaluations)\n",
        ")\n",
        "\n",
        "with timeit('2x2 20 iter cv=3'): opt.fit(train_x[:200],train_y[:200], callback = on_step)\n",
        "print(\"val. score: %s\" % opt.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "OrderedDict([('model__C', 2885), ('model__gamma', 0.0001)])"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "opt.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hLsUZ1ZnBp5P"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_info = (train_x, train_y, num_x, cat_x)\n",
        "with open('output/train_info.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wvgdkTRBptT",
        "colab_type": "code",
        "colab": {},
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "model = get_pipeline(CatBoostRegressor(silent=True))\n",
        "submit(model)\n",
        "save(model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0twqEdSiBpgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gJCjBEBBpSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2qnmlMeBonj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Jm2LQ4BoSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_BEY8s3Uowo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ridge, \t        train 0.115, test 0.143\n",
        "svm, \t        train 0.088, test 0.141\n",
        "lin, \t        train 0.089, test 0.151\n",
        "lasso, \t        train 0.109, test 0.137\n",
        "ElasticNet, \ttrain 0.399, test 0.399\n",
        "GammaRegressor, train 0.248, test 0.251\n",
        "KNeighborsRegrestrain 0.169, test 0.215\n",
        "RandomForestRegrtrain 0.056, test 0.147\n",
        "SGDRegressor, \ttrain 0.196, test 0.233\n",
        "CatBoostRegressotrain 0.032, test 0.122\n",
        "xgb.XGBRegressortrain 0.005, test 0.150\n",
        "lgb.LGBMRegressotrain 0.190, test 0.211\n",
        "HistGradientBoostrain nan, test nan\n",
        "MLPRegressor, \ttrain 0.138, test 0.196"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
      "language": "python",
      "name": "python37364bitprogramdatavirtualenv99403c2e8abd4ba0909557516bfee9d9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "colab": {
      "name": "Copy of Copy of Copy of rentJesse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}