{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "_NDWSAWprShN",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import altair as alt\n",
    "from aoc import timeit\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def load(filename):\n",
    "    f = open(filename,\"rb\")\n",
    "    return pickle.load(f)\n",
    "    \n",
    "def save(model, filename='bestmodel.pickle'):\n",
    "    with open('output/'+filename, 'wb') as handle:\n",
    "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def save_feature_selection(cols, filename='feat_selection.pickle'):\n",
    "    with open('output/'+filename, 'wb') as handle:\n",
    "        pickle.dump(cols, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def submit(model, filename='submission.csv'):\n",
    "    pred = model.predict(final_test)\n",
    "    final_test['SalePrice'] = np.exp(pred)\n",
    "    final_test[['Id','SalePrice']].to_csv('output/'+filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "colab_type": "code",
    "id": "3whduyAbrShU",
    "outputId": "ee37d5cf-5d0f-4de2-c51b-9a622e6998a2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"output/engineered_datasets.pickle\",\"rb\")\n",
    "train_x, train_y, final_test, num_x, cat_x, cat_x_ind = pickle.load(f)\n",
    "f = open(\"output/feat_selection.pickle\",\"rb\")\n",
    "cols = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab_type": "text",
    "id": "BPXAZImebs9C"
   },
   "source": [
    "## Import preprocessing pipelines & models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from utils.sklearn_custom_steps import DFSimpleImputer, DFOneHotEncoder,DFMinMaxScaler,DFColumnTransformer,DFOutlierExtractor,DFOutlierExtractor,DFStandardScaler,DFRobustScaler,DFSmartImputer, DFUnSkewer, DFPowerTransformer\n",
    "from utils.sklearn_custom_steps import get_pipeline\n",
    "from utils.model_hyperparameters import models\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet,SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_validate\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,RobustScaler\n",
    "from utils.model_hyperparameters import AutoCatBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_models(to_test,train_x=train_x,**kwargs):\n",
    "    for name in to_test:\n",
    "        print(f\"{name.ljust(20)}\", end = ': ')\n",
    "        pipe = get_pipeline(models[name].model, **models[name].preprocess, **kwargs)\n",
    "        test_pipeline(pipe, train_x = train_x)\n",
    "         \n",
    "def test_model(model,train_x = train_x,param=None):\n",
    "    if not param: param = {}\n",
    "    pipe = get_pipeline(model,**param)\n",
    "    return test_pipeline(pipe, train_x=train_x)\n",
    "\n",
    "def test_pipeline(pipe,train_x = train_x):\n",
    "    # print(train_x.shape)\n",
    "    num_fold = 5\n",
    "    \n",
    "    scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
    "    print(f\"test {-1 * sum(scores['test_score'])/num_fold:.7f}, train {-1 * sum(scores['train_score'])/num_fold:.7f}\")\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to hyperparameter search on preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"output/hyperparam_tuning.pickle\",\"rb\")\n",
    "results = pickle.load(f)\n",
    "def get_estimator(model_name, results):\n",
    "    model = get_pipeline(models[model_name].model, **models[model_name].preprocess)\n",
    "    model.set_params(**results[model_name].best_params_)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "start AutoCatBoostRegressor\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 22.1min finished\nstart ElasticNet\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.0min finished\nstart KernelRidge\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  1.2min finished\nstart Lasso\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:   37.2s finished\nstart xgb.XGBRegressor\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed: 27.3min finished\nstart lgb.LGBMRegressor\nFitting 5 folds for each of 24 candidates, totalling 120 fits\n[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:  2.8min finished\n"
    }
   ],
   "source": [
    "def hyperparam_search_pipeline(model_name, pipe):\n",
    "   print('start', model_name)\n",
    "   param_grid = {\n",
    "      # 'preprocess__col_trans__category_cat_to_num': [DFOneHotEncoder(handle_unknown=\"ignore\")],\n",
    "      # 'preprocess__col_trans__numeric__unskew_num' : [DFUnSkewer(),'passthrough'],\n",
    "      'preprocess__col_trans__numeric__scale_num' : [DFStandardScaler(),DFRobustScaler(),DFMinMaxScaler(),DFPowerTransformer()],\n",
    "      'preprocess__col_trans__numeric__impute_num__strategy': ['mean','median','most_frequent'],\n",
    "      'preprocess__col_trans__category__impute_cat__strategy': ['most_frequent','constant']}\n",
    "   search = GridSearchCV(pipe, param_grid, cv=5,scoring='neg_root_mean_squared_error',verbose=1).fit(train_x[cols], train_y)\n",
    "   frame =pd.DataFrame(search.cv_results_)\n",
    "   frame.sort_values(by='rank_test_score', inplace=True)\n",
    "   return frame\n",
    "pipe_search = dict()\n",
    "for model_name in results:\n",
    "   pipe_search[model_name] = hyperparam_search_pipeline(model_name, get_estimator(model_name, results))\n",
    "   save(pipe_search,  'hyperparam_pipe.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AutoCatBoostRegressor\nbest score -0.1153902521105318\nbest params constant mean DFMinMaxScaler\nElasticNet\nbest score -0.11587168950921545\nbest params most_frequent median DFStandardScaler\nKernelRidge\nbest score -0.11674511912812666\nbest params most_frequent median DFStandardScaler\nLasso\nbest score -0.1158660391027462\nbest params most_frequent median DFStandardScaler\nxgb.XGBRegressor\nbest score -0.11712434284626357\nbest params most_frequent most_frequent DFMinMaxScaler\nlgb.LGBMRegressor\nbest score -0.11844457036420222\nbest params constant median DFRobustScaler\n"
    }
   ],
   "source": [
    "pipe_search = load('output/hyperparam_pipe.pickle')\n",
    "for model_name, res in pipe_search.items():\n",
    "    res = res.reset_index()\n",
    "    print(model_name)\n",
    "    print('best score', res['mean_test_score'][0])\n",
    "    print('best params', \n",
    "        res['param_preprocess__col_trans__category__impute_cat__strategy'][0],\n",
    "        res['param_preprocess__col_trans__numeric__impute_num__strategy'][0],\n",
    "        res['param_preprocess__col_trans__numeric__scale_num'][0],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Test of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AutoCatBoostRegressor\ntest 0.1167024, train 0.0267797\nElasticNet\ntest 0.1176089, train 0.0997127\nKernelRidge\ntest 0.1211799, train 0.1044793\nLasso\ntest 0.1175548, train 0.0994643\nxgb.XGBRegressor\ntest 0.1217188, train 0.0448069\nlgb.LGBMRegressor\ntest 0.1217541, train 0.0508283\n"
    }
   ],
   "source": [
    "# full dataset\n",
    "for model_name in results:\n",
    "    print(model_name)\n",
    "    test_pipeline(get_estimator(model_name, results),train_x=train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "AutoCatBoostRegressor\ntest 0.1153903, train 0.0287469\nElasticNet\ntest 0.1158717, train 0.1040336\nKernelRidge\ntest 0.1167451, train 0.1066567\nLasso\ntest 0.1158660, train 0.1038959\nxgb.XGBRegressor\ntest 0.1171243, train 0.0469092\nlgb.LGBMRegressor\ntest 0.1184446, train 0.0548421\n"
    }
   ],
   "source": [
    "# selected columns dataset\n",
    "for model_name in results:\n",
    "    print(model_name)\n",
    "    test_pipeline(get_estimator(model_name, results),train_x=train_x[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "wO5qirPMBqGX"
   },
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV, callbacks\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "\n",
    "NUM_ITERATIONS = 150\n",
    "NO_IMPROVEMENT_STOP_THRES = 25\n",
    "\n",
    "def gen_opt_settings(model_name):\n",
    "    model = {'model': [models[model_name].model]}\n",
    "    for k,v in models[model_name].hyper.items():\n",
    "        model['model__'+k] = v\n",
    "    if models[model_name].hyper:\n",
    "        return (model, NUM_ITERATIONS)\n",
    "    else:\n",
    "        return (model, 1)\n",
    "\n",
    "def optimize_model(model_name,train_x = train_x, train_time = 600):\n",
    "    print('running', model_name)\n",
    "    def no_improvement_detector(optim_result):\n",
    "        score = opt.best_score_\n",
    "        # print(optim_result.x)\n",
    "        print(f\"{'best score':15}{score}\")\n",
    "        if score > opt.train_status['current_score']:\n",
    "            opt.train_status['current_score'] = score\n",
    "            opt.train_status['not_improving'] = 0\n",
    "        else:\n",
    "            opt.train_status['not_improving'] += 1\n",
    "            if opt.train_status['not_improving'] == opt.train_status['stop_thres']: return True\n",
    "    checkpointsaver = callbacks.CheckpointSaver(\"output/\" + model_name + \"_skopt.pkl\")\n",
    "    deadlinestopper = callbacks.DeadlineStopper(train_time)\n",
    "\n",
    "    opt = BayesSearchCV(\n",
    "        get_pipeline(models[model_name].model, **models[model_name].preprocess),\n",
    "        [gen_opt_settings(model_name)],\n",
    "        cv=5, \n",
    "        scoring = 'neg_root_mean_squared_error',\n",
    "        return_train_score = True,\n",
    "        random_state = 112,\n",
    "        refit=False\n",
    "        )\n",
    "    opt.train_status = { 'current_score': -100, 'not_improving': 0, 'stop_thres' :NO_IMPROVEMENT_STOP_THRES}\n",
    "    opt.fit(train_x,train_y, callback = [no_improvement_detector,checkpointsaver,deadlinestopper])\n",
    "    return opt\n",
    "\n",
    "def hashing(self): return 8398398478478 \n",
    "CatBoostRegressor.__hash__ = hashing # otherwise skopt flips\n",
    "\n",
    "# to_test = [k for k in models]\n",
    "# to_test = [\n",
    "#     'AutoCatBoostRegressor',\n",
    "#     'ElasticNet',\n",
    "#     'KernelRidge',\n",
    "#     'Lasso',\n",
    "#     'xgb.XGBRegressor',\n",
    "#     'lgb.LGBMRegressor']\n",
    "# results = {}\n",
    "# for name in to_test:\n",
    "#     results[name] = optimize_model(name, train_x[cols])\n",
    "# save(results,'hyperparam_tuning.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"output/hyperparam_tuning.pickle\",\"rb\")\n",
    "results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#summarize tuning results\n",
    "def print_results(results):\n",
    "    for model in results:\n",
    "        best_run = results[model].cv_results_['rank_test_score'].index(1)\n",
    "        mean_test_score = -1 * results[model].cv_results_['mean_test_score'][best_run]\n",
    "        std_test_score = results[model].cv_results_['std_test_score'][best_run]\n",
    "        mean_train_score = -1 * results[model].cv_results_['mean_train_score'][best_run]\n",
    "        mean_score_time = results[model].cv_results_['mean_score_time'][best_run]\n",
    "        best_params = results[model].best_params_\n",
    "        print(f\"{model:<30} Best score {mean_test_score:.4f} std {std_test_score:.4f} train {mean_train_score:.4f} time {mean_score_time:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Stacking best models from hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "def get_estimator(model_name, results):\n",
    "    model = get_pipeline(models[model_name].model, **models[model_name].preprocess)\n",
    "    model.set_params(**results[model_name].best_params_)\n",
    "    return model\n",
    "\n",
    "def get_stacked_model(results,train_x=train_x):\n",
    "    to_stack_list = [\n",
    "        'AutoCatBoostRegressor',\n",
    "        'ElasticNet',\n",
    "        'KernelRidge',\n",
    "        'Lasso',\n",
    "        'xgb.XGBRegressor',\n",
    "        'lgb.LGBMRegressor']\n",
    "\n",
    "    # to_stack_list = to_test\n",
    "    # to_stack = [(model_name, results[model_name].best_estimator_) for model_name in to_stack_list]\n",
    "    # to_stack = [(model_name, results[model_name].best_estimator_) for model_name in results]\n",
    "    to_stack = [(model_name, get_estimator(model_name, results)) for model_name in to_stack_list]\n",
    "    model = StackingRegressor(to_stack, final_estimator = (LinearRegression()), passthrough = False)\n",
    "    num_fold = 5\n",
    "    scores = cross_validate(model, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
    "    print(f\"stacking model train {-1 * sum(scores['train_score'])/num_fold:.4f}, test {-1 * sum(scores['test_score'])/num_fold:.4f}\")\n",
    "    model.fit(train_x,train_y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blending, to get rid of some of the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"output/ensemble.pickle\",\"rb\")\n",
    "model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def blend(model, filename):\n",
    "    preds = [estimator.predict(final_test) for estimator in model.estimators_]\n",
    "    # weights = np.array([0.2]*len(preds) + [(1-len(preds)*0.2)])\n",
    "    weights = np.array([1/6]*len(preds))\n",
    "    print(weights)\n",
    "    # preds.append(model.predict(final_test))\n",
    "    print(len(preds))\n",
    "    # weigh the individual models with 0.1 and the stacked regressor with the remainder\n",
    "    weighted_preds = preds * weights[:, None]\n",
    "    final_preds = np.sum(weighted_preds,axis=0)\n",
    "    final_test['SalePrice'] = np.exp(final_preds)\n",
    "    final_test[['Id','SalePrice']].to_csv('output/'+filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "hLsUZ1ZnBp5P"
   },
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false",
    "colab": {},
    "colab_type": "code",
    "id": "1wvgdkTRBptT",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d0fc40469693>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# model = get_pipeline(CatBoostRegressor(silent=True,cat_features=cat_x),onehot=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# model = model.fit(train_x,train_y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ensemble.pickle'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# model = get_pipeline(CatBoostRegressor(silent=True,cat_features=cat_x),onehot=False)\n",
    "# model = model.fit(train_x,train_y)\n",
    "submit(model)\n",
    "save(model,'ensemble.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "starting,0,selected,1800\nlen col 180\nrunning AutoCatBoostRegressor\nbest score     -0.11819243622268555\nbest score     -0.11819243622268555\nbest score     -0.11819243622268555\nbest score     -0.11819243622268555\nbest score     -0.11819243622268555\nbest score     -0.11819243622268555\nbest score     -0.11792679611086843\nbest score     -0.11792679611086843\nbest score     -0.11792679611086843\nbest score     -0.11792679611086843\nbest score     -0.11741985371097621\nbest score     -0.11683534528937319\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nbest score     -0.11543786546100078\nrunning ElasticNet\nbest score     -0.15391733415079034\nbest score     -0.13009104753971656\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.1171938468451927\nbest score     -0.11680061114818946\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nbest score     -0.11678791592323372\nrunning KernelRidge\nbest score     -0.12300536715464408\nbest score     -0.12300536715464408\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.1215205136911556\nbest score     -0.12118512876363172\nbest score     -0.12118512876363172\nbest score     -0.12118512876363172\nbest score     -0.12118512876363172\nbest score     -0.12118512876363172\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nbest score     -0.12117994306344934\nrunning Lasso\nbest score     -0.1408163758303168\nbest score     -0.13386001135451825\nbest score     -0.12652236277966397\nbest score     -0.12652236277966397\nbest score     -0.11727418658076105\nbest score     -0.11727418658076105\nbest score     -0.11727418658076105\nbest score     -0.11676614597135948\nbest score     -0.11676614597135948\nbest score     -0.11676614597135948\nbest score     -0.11676614597135948\nbest score     -0.11676614597135948\nbest score     -0.11676614597135948\nbest score     -0.11676614597135948\nbest score     -0.11669233658215702\nbest score     -0.11669233658215702\nbest score     -0.11669233658215702\nbest score     -0.11669233658215702\nbest score     -0.11669233658215702\nbest score     -0.11669233658215702\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.11669096702014319\nbest score     -0.1166588029989185\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nbest score     -0.11665744104123009\nrunning xgb.XGBRegressor\nbest score     -0.1195649545881158\nbest score     -0.1195649545881158\nbest score     -0.1195649545881158\nbest score     -0.1195649545881158\nbest score     -0.1195649545881158\nbest score     -0.1195649545881158\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11877855691137851\nbest score     -0.11812590498749083\nrunning lgb.LGBMRegressor\nbest score     -0.12590522914455252\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12162076702160504\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nbest score     -0.12020857435497825\nhyperparameter tuning done\nAutoCatBoostRegressor          Best score 0.1154 std 0.0103 train 0.0169 time 0.0898\nElasticNet                     Best score 0.1168 std 0.0112 train 0.0973 time 0.1497\nKernelRidge                    Best score 0.1212 std 0.0097 train 0.1045 time 0.1345\nLasso                          Best score 0.1167 std 0.0113 train 0.0963 time 0.1613\nxgb.XGBRegressor               Best score 0.1181 std 0.0101 train 0.0572 time 0.1075\nlgb.LGBMRegressor              Best score 0.1202 std 0.0091 train 0.0677 time 0.0953\nNone\nstacking model train 0.0537, test 0.1115\n[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n6\nstarting,16,selected,1800\nlen col 128\nrunning AutoCatBoostRegressor\nbest score     -0.11874123693675334\nbest score     -0.11762707608850737\nbest score     -0.11762707608850737\nbest score     -0.11762707608850737\nbest score     -0.11729162921721152\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11661251076882537\nbest score     -0.11615196699733579\nbest score     -0.11615196699733579\nbest score     -0.11615196699733579\nbest score     -0.11615196699733579\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nbest score     -0.11578642751322861\nrunning ElasticNet\nbest score     -0.15391736392902322\nbest score     -0.12663137052029724\nbest score     -0.11911409180114253\nbest score     -0.11911409180114253\nbest score     -0.1177088548597303\nbest score     -0.1177088548597303\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11762403249508746\nbest score     -0.11679766374890786\nbest score     -0.11679766374890786\nbest score     -0.11679766374890786\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668978839301541\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nbest score     -0.11668572900443719\nrunning KernelRidge\nbest score     -0.11899477968088376\nbest score     -0.11899477968088376\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11814607470528603\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797892382025423\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nbest score     -0.11797557871512301\nrunning Lasso\nbest score     -0.14090478493132647\nbest score     -0.12680142961606253\nbest score     -0.12416538526987972\nbest score     -0.12416538526987972\nbest score     -0.11918657628927759\nbest score     -0.11918657628927759\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11673198965214882\nbest score     -0.11670335885733245\nbest score     -0.11670335885733245\nbest score     -0.11670335885733245\nbest score     -0.11670335885733245\nbest score     -0.11670335885733245\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nbest score     -0.11667143516130343\nrunning xgb.XGBRegressor\nbest score     -0.11932296090582384\nbest score     -0.11932296090582384\nbest score     -0.11932296090582384\nbest score     -0.11932296090582384\nbest score     -0.11932296090582384\nbest score     -0.11932296090582384\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nbest score     -0.11930355596614377\nrunning lgb.LGBMRegressor\nbest score     -0.12589846155700968\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12200111053280359\nbest score     -0.12194378554599196\nbest score     -0.12194378554599196\nbest score     -0.12194378554599196\nbest score     -0.12192816785941506\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12136697763075467\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nbest score     -0.12125120288727334\nhyperparameter tuning done\nAutoCatBoostRegressor          Best score 0.1158 std 0.0096 train 0.0479 time 0.0366\nElasticNet                     Best score 0.1167 std 0.0116 train 0.1042 time 0.0919\nKernelRidge                    Best score 0.1180 std 0.0107 train 0.1061 time 0.1013\nLasso                          Best score 0.1167 std 0.0119 train 0.1030 time 0.0802\nxgb.XGBRegressor               Best score 0.1193 std 0.0106 train 0.0571 time 0.0706\nlgb.LGBMRegressor              Best score 0.1213 std 0.0097 train 0.0604 time 0.0712\nNone\nstacking model train 0.0668, test 0.1132\n[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n6\nstarting,74,selected,1800\nlen col 96\nrunning AutoCatBoostRegressor\nbest score     -0.11519915590000333\nbest score     -0.11506423805607577\nbest score     -0.11506423805607577\nbest score     -0.11425105990971038\nbest score     -0.11425105990971038\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.1141036594217491\nbest score     -0.11347851126989827\nbest score     -0.11347851126989827\nbest score     -0.11347851126989827\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nbest score     -0.11206992829875884\nrunning ElasticNet\nbest score     -0.1539158831380476\nbest score     -0.1293632288573232\nbest score     -0.11932919090359237\nbest score     -0.11932919090359237\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11648359931775014\nbest score     -0.11638391073452825\nbest score     -0.11638391073452825\nbest score     -0.11613870315731278\nbest score     -0.11613870315731278\nbest score     -0.11613870315731278\nbest score     -0.11582157937800598\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nbest score     -0.11553746326343599\nrunning KernelRidge\nbest score     -0.1167878758415471\nbest score     -0.1167878758415471\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11607386210356067\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597224260668773\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nbest score     -0.11597071600042307\nrunning Lasso\nbest score     -0.14076101751788855\nbest score     -0.13011057911166032\nbest score     -0.12572487903337004\nbest score     -0.12572487903337004\nbest score     -0.11938760428421168\nbest score     -0.11938760428421168\nbest score     -0.11531275842457672\nbest score     -0.11531275842457672\nbest score     -0.11531275842457672\nbest score     -0.11531275842457672\nbest score     -0.11531275842457672\nbest score     -0.11531275842457672\nbest score     -0.11529963908880848\nbest score     -0.11529192176807056\nbest score     -0.11528238710414214\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nbest score     -0.11526133734380227\nrunning xgb.XGBRegressor\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nbest score     -0.11583374062836159\nrunning lgb.LGBMRegressor\nbest score     -0.12450049658716866\nbest score     -0.12049428731591154\nbest score     -0.12049428731591154\nbest score     -0.12049428731591154\nbest score     -0.12049428731591154\nbest score     -0.12049428731591154\nbest score     -0.12049428731591154\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.12044705986136249\nbest score     -0.11830152178585382\nbest score     -0.11830152178585382\nbest score     -0.11830152178585382\nbest score     -0.11830152178585382\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nbest score     -0.11797054833971805\nhyperparameter tuning done\nAutoCatBoostRegressor          Best score 0.1121 std 0.0095 train 0.0496 time 0.0350\nElasticNet                     Best score 0.1155 std 0.0111 train 0.1061 time 0.0528\nKernelRidge                    Best score 0.1160 std 0.0101 train 0.1065 time 0.0993\nLasso                          Best score 0.1153 std 0.0112 train 0.1050 time 0.0927\nxgb.XGBRegressor               Best score 0.1158 std 0.0106 train 0.0474 time 0.0586\nlgb.LGBMRegressor              Best score 0.1180 std 0.0091 train 0.0676 time 0.0664\nNone\nstacking model train 0.0664, test 0.1100\n[0.16666667 0.16666667 0.16666667 0.16666667 0.16666667 0.16666667]\n6\n"
    }
   ],
   "source": [
    "feat_selector = load('output/feat_selector.pickle')\n",
    "for run_amount, strictness in [(0,'selected'),(16,'selected'),(74,'selected')]:\n",
    "    for train_time in [1800]:\n",
    "        print(f'starting,{run_amount},{strictness},{train_time}')\n",
    "        cols = set(feat_selector.named_steps['model'].runs[run_amount][strictness])\n",
    "        print('len col', len(cols))\n",
    "        to_test = [k for k in models]\n",
    "        to_test = [\n",
    "            'AutoCatBoostRegressor',\n",
    "            'ElasticNet',\n",
    "            'KernelRidge',\n",
    "            'Lasso',\n",
    "            'xgb.XGBRegressor',\n",
    "            'lgb.LGBMRegressor']\n",
    "        results = {}\n",
    "        for name in to_test:\n",
    "            results[name] = optimize_model(name, train_x[cols], train_time)\n",
    "        save(results,'hyperparam_tuning'+str(run_amount)+strictness+str(train_time))\n",
    "        print('hyperparameter tuning done')\n",
    "        print(print_results(results))\n",
    "        model = get_stacked_model(results,train_x=train_x[cols])\n",
    "        submit(model, 'submission'+str(run_amount)+strictness+str(train_time))\n",
    "        save(model, 'ensemble'+str(run_amount)+strictness+str(train_time))\n",
    "        blend(model,'blend'+str(run_amount)+strictness+str(train_time)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Copy of Copy of rentJesse.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
   "language": "python",
   "name": "python37364bitprogramdatavirtualenv99403c2e8abd4ba0909557516bfee9d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}