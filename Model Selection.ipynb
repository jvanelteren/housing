{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NDWSAWprShN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "def save(model, filename='bestmodel.pickle'):\n",
        "    with open('output/'+filename, 'wb') as handle:\n",
        "        pickle.dump(model, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "def submit(model):\n",
        "    model = model.fit(train_x,train_y)\n",
        "    pred = model.predict(final_test)\n",
        "    final_test['SalePrice'] = np.exp(pred)\n",
        "    final_test[['Id','SalePrice']].to_csv('output/submission.csv', index=False)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3whduyAbrShU",
        "colab_type": "code",
        "outputId": "ee37d5cf-5d0f-4de2-c51b-9a622e6998a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "#make train and test datasets. Splitting labels and features happens later\n",
        "path_train = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/train.csv\"\n",
        "path_test = \"https://raw.githubusercontent.com/jvanelteren/housing/master/datasets/test.csv\"\n",
        "\n",
        "train = pd.read_csv(path_train)\n",
        "final_test = pd.read_csv(path_test)\n",
        "print(train.shape, final_test.shape)\n",
        "\n",
        "y_col = (set(train.columns) - set(final_test.columns)).pop()\n",
        "train[y_col] = np.log1p(train[y_col])\n",
        "\n",
        "# since we use cross validation the train set does not have to be split anymore\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_x, test_x, train_y, test_y = train_test_split(\n",
        "#     train.drop([y_col], axis=1),train.loc[:,y_col], test_size=0.33, random_state=42) \n",
        "# ds = (train_x,test_x,train_y,test_y)\n",
        "# for d in ds: print(d.shape)\n",
        "train_x = train.drop([y_col], axis=1)\n",
        "train_y = train.loc[:,y_col]\n",
        "train_x.shape, train_y.shape\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1460, 81) (1459, 80)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1460, 80), (1460,))"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPXAZImebs9C",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d_1GRqKMm1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def correlation_ratio(categories, measurements):\n",
        "    fcat, _ = pd.factorize(categories)\n",
        "    cat_num = np.max(fcat)+1\n",
        "    y_avg_array = np.zeros(cat_num)\n",
        "    n_array = np.zeros(cat_num)\n",
        "    for i in range(0,cat_num):\n",
        "        cat_measures = measurements[np.argwhere(fcat == i).flatten()]\n",
        "        n_array[i] = len(cat_measures)\n",
        "        y_avg_array[i] = np.average(cat_measures)\n",
        "    y_total_avg = np.sum(np.multiply(y_avg_array,n_array))/np.sum(n_array)\n",
        "    numerator = np.sum(np.multiply(n_array,np.power(np.subtract(y_avg_array,y_total_avg),2)))\n",
        "    denominator = np.sum(np.power(np.subtract(measurements,y_total_avg),2))\n",
        "    if numerator == 0:\n",
        "        eta = 0.0\n",
        "    else:\n",
        "        eta = np.sqrt(numerator/denominator)\n",
        "    return eta\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi2Hnpq0JJTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "# todo multivariate imputation, possibly with pipelines for numeric and categorical data\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "# https://stackoverflow.com/questions/51237635/difference-between-standard-scaler-and-minmaxscaler/51237727\n",
        "# don't know features are normal so just going with minmax scalar atm\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "#https://stackoverflow.com/questions/36631163/what-are-the-pros-and-cons-between-get-dummies-pandas-and-onehotencoder-sciki\n",
        "#The crux of it is that the sklearn encoder creates a function which persists and can then be applied to new data sets which use the same categorical variables, with consistent results.\n",
        "# So don't use pandas get dummies, but a OneHotEncoder\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# We create the preprocessing pipelines for both numeric and categorical data.\n",
        "corr = train.corr()[y_col]\n",
        "corr = corr.sort_values(ascending=False)\n",
        "num_x = list(corr.index)[1:]\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('impute_num', SimpleImputer(strategy='median')),\n",
        "    ('scale_num', MinMaxScaler())])\n",
        "\n",
        "cat_x = [col for col in final_test.columns if final_test[col].dtype == 'object']\n",
        "cat_x.sort(key = lambda x: -correlation_ratio(train[x],train[y_col]))\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('impute_cat', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot_cat', OneHotEncoder(handle_unknown=\"ignore\"))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('numeric', numeric_transformer, num_x),\n",
        "        ('category', categorical_transformer, cat_x)])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azoNOEDFbs9F",
        "colab_type": "text"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ],
        "id": "7Zi4dfYbbs9G",
        "colab_type": "code",
        "outputId": "7ee5f87c-b225-452f-9632-d7182229d4c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "\n",
        "# from catboost import CatBoostRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV, ElasticNet,SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import cross_validate\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def inv_y(transformed_y):\n",
        "    return np.exp(transformed_y)\n",
        "\n",
        "from collections import namedtuple\n",
        "p = namedtuple('params', ['model','hyper'])\n",
        "\n",
        "models = {'RidgeCV': p(RidgeCV(),\n",
        "                {}),\n",
        "            'svm.SVR': p(svm.SVR(),\n",
        "                {'gamma': (1e-4,0.9,'log-uniform'),\n",
        "                'C': [1, 10, 100, 1000, 10000]}),\n",
        "            'LinearRegression':p(LinearRegression(),\n",
        "                {}),\n",
        "            'Lasso':p(Lasso(),\n",
        "                {'alpha':(0.005,1.0,'log-uniform')}),\n",
        "            'ElasticNet':p(ElasticNet(),\n",
        "                {}),\n",
        "            'KNeighborsRegressor':p(KNeighborsRegressor(),\n",
        "                {}),\n",
        "            'RandomForestRegressor':p(RandomForestRegressor(),\n",
        "                {}),\n",
        "            'SGDRegressor':p(SGDRegressor(),\n",
        "                {}),\n",
        "            'CatBoostRegressor':p(CatBoostRegressor(silent=True),\n",
        "                {}),\n",
        "            'xgb.XGBRegressor':p(xgb.XGBRegressor(),\n",
        "                {}),\n",
        "            'lgb.LGBMRegressor':\n",
        "                p(lgb.LGBMRegressor(num_leaves=31,\n",
        "                        learning_rate=0.05,\n",
        "                        n_estimators=20),\n",
        "                {}),\n",
        "            'HistGradientBoostingRegressor':p(HistGradientBoostingRegressor(),\n",
        "                {}),\n",
        "            'MLPRegressor':p(MLPRegressor(),\n",
        "                {})\n",
        "}\n",
        "\n",
        "def get_pipeline(model):\n",
        "    return Pipeline([('preprocess', preprocessor),\n",
        "                   ('model',model)])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RidgeCV                  train 0.115, test 0.143\nsvm.SVR                  train 0.088, test 0.141\nLinearRegression         train 0.089, test 0.151\nLasso                    train 0.399, test 0.399\nElasticNet               train 0.399, test 0.399\nKNeighborsRegressor      train 0.169, test 0.215\nRandomForestRegressor    train 0.055, test 0.147\nSGDRegressor             train 0.196, test 0.234\nCatBoostRegressor        train 0.032, test 0.122\nxgb.XGBRegressor         train 0.005, test 0.150\nlgb.LGBMRegressor        train 0.190, test 0.211\nHistGradientBoostingRegressortrain nan, test nan\nMLPRegressor             train 0.136, test 0.201\n"
        }
      ],
      "source": [
        "for name in models:\n",
        "    pipe = get_pipeline(models[name].model)\n",
        "    # score = -1 * cross_val_score(pipe, train_x, train_y,cv=3,scoring='neg_root_mean_squared_error')\n",
        "    # below is necessary for looking at train scores\n",
        "    num_fold = 3\n",
        "    scores = cross_validate(pipe, train_x, train_y, scoring='neg_root_mean_squared_error', cv=num_fold, return_train_score=True)\n",
        "    # scoring is identical to \n",
        "    # make_scorer(mean_squared_error,greater_is_better=False, root=False,squared=False)\n",
        "    # neg_mean_squared_log_error\n",
        "    print(f\"{name:<25}train {-1 * sum(scores['train_score'])/num_fold:.3f}, test {-1 * sum(scores['test_score'])/num_fold:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "dict_keys(['memory', 'steps', 'verbose', 'preprocess', 'model', 'preprocess__n_jobs', 'preprocess__remainder', 'preprocess__sparse_threshold', 'preprocess__transformer_weights', 'preprocess__transformers', 'preprocess__verbose', 'preprocess__numeric', 'preprocess__category', 'preprocess__numeric__memory', 'preprocess__numeric__steps', 'preprocess__numeric__verbose', 'preprocess__numeric__impute_num', 'preprocess__numeric__scale_num', 'preprocess__numeric__impute_num__add_indicator', 'preprocess__numeric__impute_num__copy', 'preprocess__numeric__impute_num__fill_value', 'preprocess__numeric__impute_num__missing_values', 'preprocess__numeric__impute_num__strategy', 'preprocess__numeric__impute_num__verbose', 'preprocess__numeric__scale_num__copy', 'preprocess__numeric__scale_num__feature_range', 'preprocess__category__memory', 'preprocess__category__steps', 'preprocess__category__verbose', 'preprocess__category__impute_cat', 'preprocess__category__onehot_cat', 'preprocess__category__impute_cat__add_indicator', 'preprocess__category__impute_cat__copy', 'preprocess__category__impute_cat__fill_value', 'preprocess__category__impute_cat__missing_values', 'preprocess__category__impute_cat__strategy', 'preprocess__category__impute_cat__verbose', 'preprocess__category__onehot_cat__categories', 'preprocess__category__onehot_cat__drop', 'preprocess__category__onehot_cat__dtype', 'preprocess__category__onehot_cat__handle_unknown', 'preprocess__category__onehot_cat__sparse', 'model__alpha', 'model__copy_X', 'model__fit_intercept', 'model__max_iter', 'model__normalize', 'model__positive', 'model__precompute', 'model__random_state', 'model__selection', 'model__tol', 'model__warm_start'])"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "pipe = get_pipeline(Lasso())\n",
        "pipe.get_params().keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVRX7I7yimmP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wO5qirPMBqGX"
      },
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from aoc import timeit\n",
        "\n",
        "def model_instance(model_name):\n",
        "    model = {'model': [models[model_name].model]}\n",
        "    for k,v in models[model_name].hyper.items():\n",
        "        model['model__'+k] = v\n",
        "    return (model, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n      normalize=False, positive=False, precompute=False, random_state=None,\n      selection='cyclic', tol=0.0001, warm_start=False), 0.006038940085472412]\nbest score     -0.16007995002732295\n[Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n      normalize=False, positive=False, precompute=False, random_state=None,\n      selection='cyclic', tol=0.0001, warm_start=False), 0.006038940085472412]\nbest score     -0.16007995002732295\n[Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n      normalize=False, positive=False, precompute=False, random_state=None,\n      selection='cyclic', tol=0.0001, warm_start=False), 0.006038940085472412]\nbest score     -0.16007995002732295\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 10, 0.6794963133193531]\nbest score     -0.16007995002732295\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 1, 0.0006095366332515126]\nbest score     -0.16007995002732295\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 10, 0.008729533583041073]\nbest score     -0.1395938176676152\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 10, 0.004983147464084594]\nbest score     -0.13641552272455668\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 10, 0.004983147464084594]\nbest score     -0.13641552272455668\n[SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False), 10, 0.004983147464084594]\nbest score     -0.13641552272455668\nINFO:root:2x2 20 iter cv=3, time: 0.7120555520057679\nval. score: -0.13641552272455668\n"
        }
      ],
      "source": [
        "\n",
        "# callback handler\n",
        "train_status = { 'current_score': -100, 'not_improving': 0, 'stop_thres' : 2}\n",
        "def on_step(optim_result):\n",
        "    score = opt.best_score_\n",
        "    print(optim_result.x)\n",
        "    print(f\"{'best score':15}{score}\")\n",
        "    # print(f\"{'current score':15}{train_status['current_score']}\")\n",
        "    # print(f\"{'difference':15}{train_status['current_score']-score}\")\n",
        "    # print(f\"{'nip':15}{train_status['not_improving']}\")\n",
        "\n",
        "    if score > train_status['current_score']:\n",
        "        # print('improv')\n",
        "        train_status['current_score'] = score\n",
        "        train_status['not_improving'] = 0\n",
        "    else:\n",
        "        # print('NOT')\n",
        "        train_status['not_improving'] += 1\n",
        "        if train_status['not_improving'] == train_status['stop_thres']: return True\n",
        "\n",
        "pipe = get_pipeline(svm.SVR())\n",
        "to_test = ['Lasso','svm.SVR']\n",
        "opt = BayesSearchCV(\n",
        "    pipe,\n",
        "    [model_instance(name) for name in to_test],\n",
        "    # cv=3, \n",
        "    scoring = 'neg_root_mean_squared_error',\n",
        "    return_train_score = True,\n",
        "    random_state = 112 # (parameter space, # of evaluations)\n",
        ")\n",
        "\n",
        "with timeit('2x2 20 iter cv=3'): opt.fit(train_x[:1000],train_y[:1000], callback = on_step)\n",
        "print(\"val. score: %s\" % opt.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "defaultdict(list,\n            {'split0_test_score': [-0.14298408221965533,\n              -0.16767656330500283,\n              -0.16538811396019848,\n              -0.39098486470207544,\n              -0.1762191966166481,\n              -0.19436378887283012,\n              -0.19436378887283012,\n              -0.3840473270569187,\n              -0.27165193046884645,\n              -0.37638295597408544,\n              -0.3762939490111361,\n              -0.19436378887283012,\n              -0.39098486470207544],\n             'split1_test_score': [-0.14077728538417983,\n              -0.1685965805852505,\n              -0.1662729954917832,\n              -0.40153503739948354,\n              -0.16782158150934912,\n              -0.17997399798881863,\n              -0.17997399798881863,\n              -0.39357019526097203,\n              -0.26781046573339584,\n              -0.38560468291299443,\n              -0.3855578562207297,\n              -0.17997399798881863,\n              -0.40153503739948354],\n             'split2_test_score': [-0.19084464917954697,\n              -0.20703303943877313,\n              -0.2051454503574738,\n              -0.41968215276197396,\n              -0.21472450221745237,\n              -0.20441702811318446,\n              -0.20441702811318446,\n              -0.4108022554305727,\n              -0.2869420394829703,\n              -0.40237093201158414,\n              -0.40225236341016285,\n              -0.20441702811318446,\n              -0.41968215276197396],\n             'split3_test_score': [-0.16999808937185173,\n              -0.20543972102263527,\n              -0.2027317304484356,\n              -0.42588080755760443,\n              -0.19776824665500173,\n              -0.21813745595996437,\n              -0.21813745595996437,\n              -0.4205504622090229,\n              -0.3090607207482638,\n              -0.4142046085463547,\n              -0.41414421115393235,\n              -0.21813745595996437,\n              -0.42588080755760443],\n             'split4_test_score': [-0.15579564398138088,\n              -0.1817237174226668,\n              -0.17944665929360015,\n              -0.37426141722027245,\n              -0.18061202412176966,\n              -0.1858719834356417,\n              -0.1858719834356417,\n              -0.36689882266602564,\n              -0.25512179689792647,\n              -0.35944849656071465,\n              -0.3592855109440455,\n              -0.1858719834356417,\n              -0.37426141722027245],\n             'mean_test_score': [-0.16007995002732295,\n              -0.1860939243548657,\n              -0.18379698991029825,\n              -0.40246885592828197,\n              -0.18742911022404418,\n              -0.19655285087408786,\n              -0.19655285087408786,\n              -0.3951738125247024,\n              -0.2781173906662806,\n              -0.3876023352011467,\n              -0.3875067781480013,\n              -0.19655285087408786,\n              -0.40246885592828197],\n             'std_test_score': [0.01859060536240029,\n              0.017188143150853385,\n              0.017199904844574516,\n              0.018829926908901982,\n              0.016784076826090052,\n              0.01357550547888056,\n              0.01357550547888056,\n              0.019047665975464725,\n              0.018505114499491018,\n              0.019226523939489874,\n              0.01925071883539597,\n              0.01357550547888056,\n              0.018829926908901982],\n             'rank_test_score': [1, 3, 2, 12, 4, 5, 5, 11, 8, 10, 9, 5, 12],\n             'split0_train_score': [-0.15656477977565367,\n              -0.18252960242410032,\n              -0.1800888601702338,\n              -0.0927444459424231,\n              -0.1864027593500541,\n              -0.07818639818766254,\n              -0.07818639818766254,\n              -0.09206238774851823,\n              -0.08425258657670613,\n              -0.10015435132532031,\n              -0.09135745287443184,\n              -0.07818639818766254,\n              -0.0927444459424231],\n             'split1_train_score': [-0.15750328920302845,\n              -0.18344178336301856,\n              -0.18116816298315105,\n              -0.09256580454804426,\n              -0.1864944691863366,\n              -0.07901656035036024,\n              -0.07901656035036024,\n              -0.09210841613156381,\n              -0.08423727715053268,\n              -0.1012694418301049,\n              -0.09148244005931463,\n              -0.07901656035036024,\n              -0.09256580454804426],\n             'split2_train_score': [-0.14123516542402131,\n              -0.16707715301081627,\n              -0.16463887458507334,\n              -0.09266255697918889,\n              -0.17061851158277858,\n              -0.07811610132535543,\n              -0.07811610132535543,\n              -0.09208762686883701,\n              -0.08417871427164589,\n              -0.09814116865417269,\n              -0.09148544468762852,\n              -0.07811610132535543,\n              -0.09266255697918889],\n             'split3_train_score': [-0.15424346854830692,\n              -0.18182127718496946,\n              -0.17949654884484886,\n              -0.09293521515699031,\n              -0.17914819088240996,\n              -0.07933223667946046,\n              -0.07933223667946046,\n              -0.09236700658147416,\n              -0.0844763926247407,\n              -0.09963487565982115,\n              -0.0916121249386124,\n              -0.07933223667946046,\n              -0.09293521515699031],\n             'split4_train_score': [-0.15451660907633677,\n              -0.18062352454417777,\n              -0.17822512492002904,\n              -0.09308844549497211,\n              -0.1821779804540151,\n              -0.07973933192935315,\n              -0.07973933192935315,\n              -0.09252724264410644,\n              -0.08471191993116922,\n              -0.0984938105325781,\n              -0.09202781976006054,\n              -0.07973933192935315,\n              -0.09308844549497211],\n             'mean_train_score': [-0.15281266240546942,\n              -0.17909866810541647,\n              -0.1767235143006672,\n              -0.09279929362432374,\n              -0.18096838229111886,\n              -0.07887812569443838,\n              -0.07887812569443838,\n              -0.09223053599489994,\n              -0.08437137811095893,\n              -0.09953872960039943,\n              -0.09159305646400959,\n              -0.07887812569443838,\n              -0.09279929362432374],\n             'std_train_score': [0.0059172534396390135,\n              0.006080930405267524,\n              0.00611659262700448,\n              0.00018884162381018217,\n              0.0058645739581244735,\n              0.0006365885959456986,\n              0.0006365885959456986,\n              0.000184536808673941,\n              0.00019809625468098974,\n              0.0011338987125580286,\n              0.00023182237387371044,\n              0.0006365885959456986,\n              0.00018884162381018217],\n             'mean_fit_time': [0.3072185039520264,\n              0.258650541305542,\n              0.24125895500183106,\n              0.707788610458374,\n              0.5007048606872558,\n              0.5496825695037841,\n              0.569481897354126,\n              0.7461719989776612,\n              0.6268414974212646,\n              0.7359842300415039,\n              0.8525080680847168,\n              0.6020520687103271,\n              0.8223258972167968],\n             'std_fit_time': [0.06503560506741948,\n              0.029224345522489953,\n              0.029948371427579962,\n              0.12472317301523828,\n              0.07057011038916107,\n              0.10389310107332596,\n              0.02054134199327988,\n              0.07171407049404463,\n              0.04998794653630619,\n              0.11801119306076953,\n              0.1263879697349544,\n              0.04141614152051996,\n              0.06270538899214373],\n             'mean_score_time': [0.04398455619812012,\n              0.04117155075073242,\n              0.03278083801269531,\n              0.13772025108337402,\n              0.11913843154907226,\n              0.11653857231140137,\n              0.12012577056884766,\n              0.15711040496826173,\n              0.13351845741271973,\n              0.16130461692810058,\n              0.21007781028747557,\n              0.11813230514526367,\n              0.17149653434753417],\n             'std_score_time': [0.008736967251896766,\n              0.010785738831132687,\n              0.010678302851421415,\n              0.021717083126737938,\n              0.012630692993023374,\n              0.016902430094039925,\n              0.01423957061247081,\n              0.023137701333619275,\n              0.02092351873603246,\n              0.023264415818234466,\n              0.02664344168336421,\n              0.03337764321976,\n              0.029566368762283496],\n             'param_model': [Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n                    max_iter=1000, normalize=False, positive=False, precompute=False,\n                    random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n              Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n                    max_iter=1000, normalize=False, positive=False, precompute=False,\n                    random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n              Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n                    max_iter=1000, normalize=False, positive=False, precompute=False,\n                    random_state=None, selection='cyclic', tol=0.0001, warm_start=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n              SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)],\n             'param_model__alpha': [0.006038940085472412,\n              0.010286584241890518,\n              0.009911927539456366],\n             'params': [OrderedDict([('model',\n                            Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n                                  max_iter=1000, normalize=False, positive=False, precompute=False,\n                                  random_state=None, selection='cyclic', tol=0.0001, warm_start=False)),\n                           ('model__alpha', 0.006038940085472412)]),\n              OrderedDict([('model',\n                            Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n                                  max_iter=1000, normalize=False, positive=False, precompute=False,\n                                  random_state=None, selection='cyclic', tol=0.0001, warm_start=False)),\n                           ('model__alpha', 0.010286584241890518)]),\n              OrderedDict([('model',\n                            Lasso(alpha=0.006038940085472412, copy_X=True, fit_intercept=True,\n                                  max_iter=1000, normalize=False, positive=False, precompute=False,\n                                  random_state=None, selection='cyclic', tol=0.0001, warm_start=False)),\n                           ('model__alpha', 0.009911927539456366)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 10),\n                           ('model__gamma', 0.9)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 1),\n                           ('model__gamma', 0.001)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 10),\n                           ('model__gamma', 0.1)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 10),\n                           ('model__gamma', 0.1)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 1000),\n                           ('model__gamma', 0.6)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 10),\n                           ('model__gamma', 0.2)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 1),\n                           ('model__gamma', 0.5)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 10),\n                           ('model__gamma', 0.5)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 100),\n                           ('model__gamma', 0.1)]),\n              OrderedDict([('model',\n                            SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n                                kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)),\n                           ('model__C', 1000),\n                           ('model__gamma', 0.9)])],\n             'rank_train_score': [10, 12, 11, 7, 13, 1, 1, 6, 4, 9, 5, 1, 7],\n             'param_model__C': [10, 1, 10, 10, 1000, 10, 1, 10, 100, 1000],\n             'param_model__gamma': [0.9,\n              0.001,\n              0.1,\n              0.1,\n              0.6,\n              0.2,\n              0.5,\n              0.5,\n              0.1,\n              0.9]})"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "opt.cv_results_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "OrderedDict([('model__C', 2885), ('model__gamma', 0.0001)])"
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "opt.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "hLsUZ1ZnBp5P"
      },
      "source": [
        "## Saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_info = (train_x, train_y, num_x, cat_x)\n",
        "with open('output/train_info.pickle', 'wb') as handle:\n",
        "    pickle.dump(train_info, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wvgdkTRBptT",
        "colab_type": "code",
        "colab": {},
        "tags": [
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend",
          "outputPrepend"
        ]
      },
      "source": [
        "model = get_pipeline(CatBoostRegressor(silent=True))\n",
        "submit(model)\n",
        "save(model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0twqEdSiBpgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gJCjBEBBpSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2qnmlMeBonj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Jm2LQ4BoSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_BEY8s3Uowo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ridge, \t        train 0.115, test 0.143\n",
        "svm, \t        train 0.088, test 0.141\n",
        "lin, \t        train 0.089, test 0.151\n",
        "lasso, \t        train 0.109, test 0.137\n",
        "ElasticNet, \ttrain 0.399, test 0.399\n",
        "GammaRegressor, train 0.248, test 0.251\n",
        "KNeighborsRegrestrain 0.169, test 0.215\n",
        "RandomForestRegrtrain 0.056, test 0.147\n",
        "SGDRegressor, \ttrain 0.196, test 0.233\n",
        "CatBoostRegressotrain 0.032, test 0.122\n",
        "xgb.XGBRegressortrain 0.005, test 0.150\n",
        "lgb.LGBMRegressotrain 0.190, test 0.211\n",
        "HistGradientBoostrain nan, test nan\n",
        "MLPRegressor, \ttrain 0.138, test 0.196"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
      "language": "python",
      "name": "python37364bitprogramdatavirtualenv99403c2e8abd4ba0909557516bfee9d9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "colab": {
      "name": "Copy of Copy of Copy of rentJesse.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}