{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from fastai2.tabular.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "f = open(\"output/engineered_datasets.pickle\",\"rb\")\n",
    "train_x, train_y, final_test, num_x, cat_x, cat_x_ind = pickle.load(f)\n",
    "train_x['SalePrice'] = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dls = TabularDataLoaders.from_df(train_x, path='bla', y_names=\"SalePrice\",\n",
    "    cat_names = cat_x,\n",
    "    cont_names = num_x,\n",
    "    procs = [Categorify, FillMissing, Normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>_rmse</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>138.684082</td>\n",
       "      <td>128.327133</td>\n",
       "      <td>11.328156</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>103.545525</td>\n",
       "      <td>72.257744</td>\n",
       "      <td>8.500455</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>74.207130</td>\n",
       "      <td>59.734009</td>\n",
       "      <td>7.728777</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "learn = tabular_learner(dls, loss_func=MSELossFlat(), \n",
    "                        metrics=rmse)\n",
    "learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# final_test.drop(columns=['Id','Utilities'], inplace=True)\n",
    "final_test['BsmtFinSF1'] = final_test['BsmtFinSF1'].fillna(0)\n",
    "final_test['BsmtFinSF2'] = final_test['BsmtFinSF2'].fillna(0)\n",
    "final_test['BsmtUnfSF'] = final_test['BsmtUnfSF'].fillna(0)\n",
    "final_test['TotalBsmtSF'] = final_test['TotalBsmtSF'].fillna(0)\n",
    "final_test['BsmtFullBath'] = final_test['BsmtFullBath'].fillna(0)\n",
    "final_test['KitchenQual'] = final_test['KitchenQual'].fillna(train_x['KitchenQual'].mean())\n",
    "final_test['Functional'] = final_test['Functional'].fillna(train_x['Functional'].mean())\n",
    "final_test['GarageCars'] = final_test['GarageCars'].fillna(0)\n",
    "final_test['GarageArea'] = final_test['GarageArea'].fillna(0)\n",
    "final_test['SimplFunctional'] = final_test['SimplFunctional'].fillna(0)\n",
    "final_test['SimplKitchenQual'] = final_test['SimplKitchenQual'].fillna(0)\n",
    "final_test['KitchenScore'] = final_test['KitchenScore'].fillna(0)\n",
    "final_test['SimplFunctional'] = final_test['SimplFunctional'].fillna(train_x['SimplFunctional'].mean())\n",
    "final_test['SimplKitchenScore'] = final_test['SimplKitchenScore'].fillna(train_x['SimplKitchenScore'].mean())\n",
    "final_test['TotalBath'] = final_test['TotalBath'].fillna(1)\n",
    "final_test['AllSF'] = final_test['AllSF'].fillna(train_x['AllSF'].mean())\n",
    "final_test['AllSF_2'] = final_test['AllSF_2'].fillna(train_x['AllSF_2'].mean())\n",
    "final_test['AllSF_3'] = final_test['AllSF_3'].fillna(train_x['AllSF_3'].mean())\n",
    "final_test['AllSF_sq'] = final_test['AllSF_sq'].fillna(train_x['AllSF_sq'].mean())\n",
    "final_test['GarageCars_2'] = final_test['GarageCars_2'].fillna(train_x['GarageCars_2'].mean())\n",
    "final_test['GarageCars_3'] = final_test['GarageCars_3'].fillna(train_x['GarageCars_3'].mean())\n",
    "final_test['GarageCars_sq'] = final_test['GarageCars_sq'].fillna(train_x['GarageCars_sq'].mean())\n",
    "final_test['TotalBath_2'] = final_test['TotalBath_2'].fillna(train_x['TotalBath_2'].mean())\n",
    "final_test['TotalBath_3'] = final_test['TotalBath_3'].fillna(train_x['TotalBath_3'].mean())\n",
    "final_test['TotalBath_sq'] = final_test['TotalBath_sq'].fillna(train_x['TotalBath_sq'].mean())\n",
    "final_test['TotalBath_sq'] = final_test['TotalBath_sq'].fillna(train_x['TotalBath_sq'].mean())\n",
    "final_test['KitchenQual_2'] = final_test['KitchenQual_2'].fillna(train_x['KitchenQual_2'].mean())\n",
    "final_test['KitchenQual_3'] = final_test['KitchenQual_3'].fillna(train_x['KitchenQual_3'].mean())\n",
    "final_test['KitchenQual_sq'] = final_test['KitchenQual_sq'].fillna(train_x['KitchenQual_sq'].mean())\n",
    "final_test['BsmtFinSF1_log'] = final_test['BsmtFinSF1_log'].fillna(train_x['BsmtFinSF1_log'].mean())\n",
    "final_test['BsmtFinSF2_log'] = final_test['BsmtFinSF2_log'].fillna(train_x['BsmtFinSF2_log'].mean())\n",
    "final_test['BsmtUnfSF_log'] = final_test['BsmtUnfSF_log'].fillna(train_x['BsmtUnfSF_log'].mean())\n",
    "final_test['TotalBsmtSF_log'] = final_test['TotalBsmtSF_log'].fillna(train_x['TotalBsmtSF_log'].mean())\n",
    "final_test['BsmtFullBath_log'] = final_test['BsmtFullBath_log'].fillna(train_x['BsmtFullBath_log'].mean())\n",
    "final_test['TotalBsmtSF_log'] = final_test['TotalBsmtSF_log'].fillna(train_x['TotalBsmtSF_log'].mean())\n",
    "final_test['BsmtHalfBath_log'] = final_test['BsmtHalfBath_log'].fillna(train_x['BsmtHalfBath_log'].mean())\n",
    "final_test['GarageCars_log'] = final_test['GarageCars_log'].fillna(train_x['GarageCars_log'].mean())\n",
    "final_test['GarageArea_log'] = final_test['GarageArea_log'].fillna(train_x['GarageArea_log'].mean())\n",
    "final_test['AllSF_log'] = final_test['AllSF_log'].fillna(train_x['AllSF_log'].mean())\n",
    "final_test['BsmtHalfBath'] = final_test['BsmtHalfBath'].fillna(train_x['BsmtHalfBath'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final_test['MiscFeature']=np.nan\n",
    "dl = learn.dls.test_dl(final_test)\n",
    "res= learn.get_preds(dl=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shed'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[6,'MiscFeature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     1373\n",
       "Shed      40\n",
       "Othr       1\n",
       "Name: MiscFeature, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MiscFeature'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['MiscFeature']=np.nan\n",
    "dl = learn.dls.test_dl(test)\n",
    "res= learn.get_preds(dl=dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.9217]]), None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'LandContour',\n",
       " 'LotConfig',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'important_feature_poisson': np.random.poisson(3, 1000),\n",
    "        'important_feature_dummy': np.random.binomial(1,0.5,1000),\n",
    "        'random_feature_normal': np.random.normal(0,100,1000),\n",
    "        'random_feature_dummy': np.random.binomial(1,0.5,1000)\n",
    "    }\n",
    ")\n",
    "\n",
    "data['Y'] = np.random.normal(10,3,1000) * data['important_feature_poisson'] + np.random.normal(10,3,1000) * data['important_feature_dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n                      max_samples=None, min_impurity_decrease=0.0,\n                      min_impurity_split=None, min_samples_leaf=1,\n                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n                      n_estimators=100, n_jobs=None, oob_score=True,\n                      random_state=1, verbose=0, warm_start=False)"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X = data.drop(['Y'], axis=1)\n",
    "Y = data['Y']\n",
    "reg = RandomForestRegressor(random_state=1,oob_score=True)\n",
    "reg.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.columns.values\n",
    "importances = reg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array(['important_feature_poisson', 'random_feature_normal',\n       'important_feature_dummy', 'random_feature_dummy'], dtype=object)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "features[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array(['important_feature_poisson', 'important_feature_dummy',\n        'random_feature_normal', 'random_feature_dummy'], dtype=object),\n array([0.69297502, 0.05833626, 0.2287804 , 0.01990832]))"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "features,importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.69297502, 0.05833626, 0.2287804 , 0.01990832])"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([ 5,  3,  1,  6,  0,  4,  2,  8,  7,  9, 10, 11])"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "X['important_feature_poisson'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://medium.com/turo-engineering/how-not-to-use-random-forest-265a19a68576\n",
    "https://www.kdnuggets.com/2019/10/feature-selection-beyond-feature-importance.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'ShuffleSplit' from 'sklearn' (C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\__init__.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-91578ad78045>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# X = X.as_matrix()/\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m## Pseudo code:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ShuffleSplit' from 'sklearn' (C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# X = X.as_matrix()/\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "scores = defaultdict(list)\n",
    "## Pseudo code:\n",
    "# For 100 random draw of train / test (70%/30%):\n",
    "    # fit a random forest \n",
    "    # compute the accuracy (acc) \n",
    "    # For each feature: \n",
    "        # randomly permute the observations of the feature\n",
    "        # compute the accuracy with random permutation (shuff_acc)\n",
    "        # compute the decrease in accuracy between acc and shuff_acc\n",
    "        # store this value\n",
    "# compute the mean decrease accuracy over the 100 draws for each feature\n",
    "for train_idx, test_idx in ShuffleSplit(len(X), 100, .3):\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    Y_train, Y_test = Y[train_idx], Y[test_idx]\n",
    "    rf = reg.fit(X_train, Y_train)\n",
    "    acc = r2_score(Y_test, rf.predict(X_test))\n",
    "    for i in range(X.shape[1]):\n",
    "        X_t = X_test.copy()\n",
    "        np.random.shuffle(X_t[:, i])\n",
    "        shuff_acc = r2_score(Y_test, rf.predict(X_t))\n",
    "        scores[features[i]].append((acc-shuff_acc)/acc)\n",
    "mda_features = [f for f in scores.keys()]\n",
    "mda_importance = [(np.mean(score)) for score in scores.values()]\n",
    "mda_indices = np.argsort(mda_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([12.02194951, 12.02194951, 12.02194951, 12.02194951,\n",
    "       12.02194951, 12.02194951])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.array([a,a,a,a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,6) (1,4) ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b8e12bb7a4e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,6) (1,4) "
     ]
    }
   ],
   "source": [
    "res* np.array([[1,2,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([12.02194951, 12.02194951, 12.02194951, 12.02194951, 12.02194951,\n       12.02194951])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "weights = np.array([0.1,0.2,0.6,0.1])\n",
    "weighted_preds = preds * weights[:, None]\n",
    "final_preds = np.sum(weighted_preds,axis=0)\n",
    "final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "np.array([0.1]*7 + [0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('ProgramData': virtualenv)",
   "language": "python",
   "name": "python37364bitprogramdatavirtualenv99403c2e8abd4ba0909557516bfee9d9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}